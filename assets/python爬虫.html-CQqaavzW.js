import{_ as a}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as n,d as l,o as e}from"./app-BAoNGAQX.js";const p={};function o(t,s){return e(),n("div",null,s[0]||(s[0]=[l(`<h2 id="第一个python爬虫程序" tabindex="-1"><a class="header-anchor" href="#第一个python爬虫程序"><span>第一个Python爬虫程序</span></a></h2><p>下面使用 Python 内置的<code>urllib</code>库获取网页的 html 信息。注意，<code>urllib</code>库属于 Python 的标准库模块，无须单独安装，它是 Python 爬虫的常用模块。</p><h3 id="获取网页html信息" tabindex="-1"><a class="header-anchor" href="#获取网页html信息"><span>获取网页html信息</span></a></h3><h4 id="_1-获取响应对象" tabindex="-1"><a class="header-anchor" href="#_1-获取响应对象"><span>1. 获取响应对象</span></a></h4><p>向<a href="http://www.baidu.com/" target="_blank" rel="noopener noreferrer">百度</a>发起请求，获取百度首页的 HTML 信息：</p><div class="language-python" data-highlighter="shiki" data-ext="python" data-title="python" style="background-color:#0a0c10;color:#f0f3f6;"><pre class="shiki github-dark-high-contrast vp-code"><code><span class="line"><span style="color:#BDC4CC;"># 导包,发起请求使用urllib库的request请求模块</span></span>
<span class="line"><span style="color:#BDC4CC;"># 另外一种导包方式</span></span>
<span class="line"><span style="color:#BDC4CC;"># from urllib import request</span></span>
<span class="line"><span style="color:#FF9492;">import</span><span style="color:#F0F3F6;"> urllib.request</span></span>
<span class="line"><span style="color:#BDC4CC;"># urlopen()向URL发请求,返回响应对象,注意url必须完整</span></span>
<span class="line"><span style="color:#F0F3F6;">response</span><span style="color:#FF9492;">=</span><span style="color:#F0F3F6;">urllib.request.urlopen(</span><span style="color:#ADDCFF;">&#39;http://www.baidu.com/&#39;</span><span style="color:#F0F3F6;">)</span></span>
<span class="line"><span style="color:#91CBFF;">print</span><span style="color:#F0F3F6;">(response)</span></span></code></pre></div><p>上述代码会返回百度首页的响应对象， 其中<code>urlopen()</code>表示打开一个网页地址。注意：请求的<code>url</code>必须带有<code>http</code>或者<code>https</code>传输协议。</p><p>输出结果：</p><div class="language-" data-highlighter="shiki" data-ext="" data-title="" style="background-color:#0a0c10;color:#f0f3f6;"><pre class="shiki github-dark-high-contrast vp-code"><code><span class="line"><span>&lt;http.client.HTTPResponse object at 0x00000266F8D58D60&gt;</span></span></code></pre></div><h4 id="_2-输出html信息" tabindex="-1"><a class="header-anchor" href="#_2-输出html信息"><span>2. 输出HTML信息</span></a></h4><div class="language-python" data-highlighter="shiki" data-ext="python" data-title="python" style="background-color:#0a0c10;color:#f0f3f6;"><pre class="shiki github-dark-high-contrast vp-code"><code><span class="line"><span style="color:#FF9492;">import</span><span style="color:#F0F3F6;"> urllib.request</span></span>
<span class="line"><span style="color:#F0F3F6;">response</span><span style="color:#FF9492;">=</span><span style="color:#F0F3F6;">urllib.request.urlopen(</span><span style="color:#ADDCFF;">&#39;http://www.baidu.com/&#39;</span><span style="color:#F0F3F6;">)</span></span>
<span class="line"><span style="color:#BDC4CC;">#提取响应内容</span></span>
<span class="line"><span style="color:#F0F3F6;">html </span><span style="color:#FF9492;">=</span><span style="color:#F0F3F6;"> response.read().decode(</span><span style="color:#ADDCFF;">&#39;utf-8&#39;</span><span style="color:#F0F3F6;">)</span></span>
<span class="line"><span style="color:#BDC4CC;">#打印响应内容</span></span>
<span class="line"><span style="color:#91CBFF;">print</span><span style="color:#F0F3F6;">(html)</span></span></code></pre></div><p>输出结果：</p><div class="language-" data-highlighter="shiki" data-ext="" data-title="" style="background-color:#0a0c10;color:#f0f3f6;"><pre class="shiki github-dark-high-contrast vp-code"><code><span class="line"><span>&lt;!DOCTYPE html&gt;&lt;!--STATUS OK--&gt;&lt;html&gt;&lt;head&gt;&lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html;charset=utf-8&quot;&gt;&lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;IE=edge,chrome=1&quot;&gt;&lt;meta content=&quot;always&quot; name=&quot;referrer&quot;&gt;&lt;meta name=&quot;theme-color&quot; content=&quot;#ffffff&quot;&gt;&lt;meta name=&quot;description&quot; content=&quot;全球领先的中文搜索引擎、致力于让网民更便捷地获取信息，找到所求。百度超过千亿的中文网页数据库，可以瞬间找到相关的搜索结果。&quot;&gt;&lt;link ...</span></span></code></pre></div><p>通过调用<code>response</code>响应对象的<code>read()</code>方法提取 HTML 信息，该方法返回的结果是字节串类型(<code>bytes</code>)，因此需要使用<code>decode()</code>转换为字符串。</p><p>通过上述代码获取了百度首页的 html 信息，这是最简单、最初级的爬虫程序。</p><h3 id="urllib常用方法" tabindex="-1"><a class="header-anchor" href="#urllib常用方法"><span>urllib常用方法</span></a></h3><p><code>Request()</code>方法用于创建请求对象、包装请求头，比如重构<code>User-Agent</code>（即用户代理，指用户使用的浏览器）使程序更像人类的请求，而非机器。重构<code>User-Agent</code>是爬虫和反爬虫斗争的第一步。</p><p><code>urllib.request.Request(url,headers)</code><br> 参数说明：</p><ul><li><code>url</code>：请求的URL地址。</li><li><code>headers</code>：重构请求头。</li></ul><p><code>html</code>响应对象方法</p><div class="language-" data-highlighter="shiki" data-ext="" data-title="" style="background-color:#0a0c10;color:#f0f3f6;"><pre class="shiki github-dark-high-contrast vp-code"><code><span class="line"><span>bytes = response.read() # read()返回结果为 bytes 数据类型</span></span>
<span class="line"><span>string = response.read().decode() # decode()将字节串转换为 string 类型</span></span>
<span class="line"><span>url = response.geturl() # 返回响应对象的URL地址</span></span>
<span class="line"><span>code = response.getcode() # 返回请求时的HTTP响应码</span></span></code></pre></div><h2 id="user-agent-用户代理" tabindex="-1"><a class="header-anchor" href="#user-agent-用户代理"><span>User-Agent（用户代理）</span></a></h2><p><code>User-Agent</code>即用户代理，简称“UA”，它是一个特殊字符串头。网站服务器通过识别 “UA”来确定用户所使用的操作系统版本、CPU 类型、浏览器版本等信息。而网站服务器则通过判断 UA 来给客户端发送不同的页面。</p><p>常见的<code>User-Agent</code>请求头：</p><table><thead><tr><th>系统</th><th>浏览器</th><th style="text-align:left;">User-Agent字符串</th></tr></thead><tbody><tr><td>Mac</td><td>Chrome</td><td style="text-align:left;">Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.75 Safari/537.36</td></tr><tr><td>Mac</td><td>Firefox</td><td style="text-align:left;">Mozilla/5.0 (Macintosh; Intel Mac OS X 10.12; rv:65.0) Gecko/20100101 Firefox/65.0</td></tr><tr><td>Mac</td><td>Safari</td><td style="text-align:left;">Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/12.0.3 Safari/605.1.15</td></tr><tr><td>Windows</td><td>Edge</td><td style="text-align:left;">Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/64.0.3282.140 Safari/537.36 Edge/18.17763</td></tr><tr><td>Windows</td><td>IE</td><td style="text-align:left;">Mozilla/5.0 (Windows NT 10.0; WOW64; Trident/7.0; rv:11.0) like Gecko</td></tr><tr><td>Windows</td><td>Chrome</td><td style="text-align:left;">Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/72.0.3626.121 Safari/537.36</td></tr><tr><td>iOS</td><td>Chrome</td><td style="text-align:left;">Mozilla/5.0 (iPhone; CPU iPhone OS 7_0_4 like Mac OS X) AppleWebKit/537.51.1 (KHTML, like Gecko) CriOS/31.0.1650.18 Mobile/11B554a Safari/8536.25</td></tr><tr><td>iOS</td><td>Safari</td><td style="text-align:left;">Mozilla/5.0 (iPhone; CPU iPhone OS 8_3 like Mac OS X) AppleWebKit/600.1.4 (KHTML, like Gecko) Version/8.0 Mobile/12F70 Safari/600.1.4</td></tr><tr><td>Android</td><td>Chrome</td><td style="text-align:left;">Mozilla/5.0 (Linux; Android 4.2.1; M040 Build/JOP40D) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/31.0.1650.59 Mobile Safari/537.36</td></tr><tr><td>Android</td><td>Webkit</td><td style="text-align:left;">Mozilla/5.0 (Linux; U; Android 4.4.4; zh-cn; M351 Build/KTU84P) AppleWebKit/534.30 (KHTML, like Gecko) Version/4.0 Mobile Safari/534.30</td></tr></tbody></table><p>使用上表中的浏览器 UA，我们可以很方便的构建出<code>User-Agent</code>。通过<a href="https://useragent.buyaocha.com/#google_vignette" target="_blank" rel="noopener noreferrer">在线识别工具</a>，可以查看本机的浏览器版本以及 UA 信息：</p><table><thead><tr><th></th><th style="text-align:left;"></th></tr></thead><tbody><tr><td>浏览器名字</td><td style="text-align:left;">Chrome</td></tr><tr><td>浏览器版本</td><td style="text-align:left;">131.0.0.0</td></tr><tr><td>系统平台</td><td style="text-align:left;">Windows</td></tr><tr><td>原始UA信息</td><td style="text-align:left;">Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36</td></tr></tbody></table><h3 id="爬虫程序ua信息" tabindex="-1"><a class="header-anchor" href="#爬虫程序ua信息"><span>爬虫程序UA信息</span></a></h3><p>通过向 <a href="http://httpbin.org/" target="_blank" rel="noopener noreferrer">HTTP 测试网站</a>发送 GET 请求来查看请求头信息，从而获取爬虫程序的 UA。</p><div class="language-python" data-highlighter="shiki" data-ext="python" data-title="python" style="background-color:#0a0c10;color:#f0f3f6;"><pre class="shiki github-dark-high-contrast vp-code"><code><span class="line"><span style="color:#FF9492;">import</span><span style="color:#F0F3F6;"> urllib.request</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F0F3F6;">res </span><span style="color:#FF9492;">=</span><span style="color:#F0F3F6;"> urllib.request.urlopen(</span><span style="color:#ADDCFF;">&#39;http://httpbin.org/get&#39;</span><span style="color:#F0F3F6;">)</span></span>
<span class="line"><span style="color:#F0F3F6;">html </span><span style="color:#FF9492;">=</span><span style="color:#F0F3F6;"> res.read().decode(</span><span style="color:#ADDCFF;">&#39;utf-8&#39;</span><span style="color:#F0F3F6;">)</span></span>
<span class="line"><span style="color:#91CBFF;">print</span><span style="color:#F0F3F6;">(html)</span></span></code></pre></div><p>程序运行后，输出的请求头信息如下所示：</p><div class="language-" data-highlighter="shiki" data-ext="" data-title="" style="background-color:#0a0c10;color:#f0f3f6;"><pre class="shiki github-dark-high-contrast vp-code"><code><span class="line"><span>{</span></span>
<span class="line"><span>  &quot;args&quot;: {}, </span></span>
<span class="line"><span>  &quot;headers&quot;: {</span></span>
<span class="line"><span>    &quot;Accept-Encoding&quot;: &quot;identity&quot;, </span></span>
<span class="line"><span>    &quot;Host&quot;: &quot;httpbin.org&quot;, </span></span>
<span class="line"><span>    &quot;User-Agent&quot;: &quot;Python-urllib/3.13&quot;, </span></span>
<span class="line"><span>    &quot;X-Amzn-Trace-Id&quot;: &quot;Root=1-675ff4b8-6f0bcc827057cbbd34b40e70&quot;</span></span>
<span class="line"><span>  }, </span></span>
<span class="line"><span>  &quot;origin&quot;: &quot;27.187.253.34&quot;, </span></span>
<span class="line"><span>  &quot;url&quot;: &quot;http://httpbin.org/get&quot;</span></span>
<span class="line"><span>}</span></span></code></pre></div><p>从输出结果可以看出，<code>User-Agent</code>竟然是<code>Python-urllib/3.13</code>，这显然是爬虫程序访问网站。因此就需要重构<code>User-Agent</code>，将其伪装成“浏览器”访问网站。</p><h3 id="重构爬虫ua信息" tabindex="-1"><a class="header-anchor" href="#重构爬虫ua信息"><span>重构爬虫UA信息</span></a></h3><div class="language-python" data-highlighter="shiki" data-ext="python" data-title="python" style="background-color:#0a0c10;color:#f0f3f6;"><pre class="shiki github-dark-high-contrast vp-code"><code><span class="line"><span style="color:#FF9492;">from</span><span style="color:#F0F3F6;"> urllib </span><span style="color:#FF9492;">import</span><span style="color:#F0F3F6;"> request</span></span>
<span class="line"><span style="color:#BDC4CC;"># 定义变量：URL 与 headers</span></span>
<span class="line"><span style="color:#F0F3F6;">url </span><span style="color:#FF9492;">=</span><span style="color:#ADDCFF;"> &#39;http://httpbin.org/get&#39;</span><span style="color:#BDC4CC;"> #向测试网站发送请求</span></span>
<span class="line"><span style="color:#BDC4CC;">#重构请求头，伪装成 Mac火狐浏览器访问，可以使用上表中任意浏览器的UA信息</span></span>
<span class="line"><span style="color:#F0F3F6;">headers </span><span style="color:#FF9492;">=</span><span style="color:#F0F3F6;"> {</span></span>
<span class="line"><span style="color:#ADDCFF;">	&#39;User-Agent&#39;</span><span style="color:#F0F3F6;">:</span><span style="color:#ADDCFF;">&#39;Mozilla/5.0 (Macintosh; Intel Mac OS X 10.12; rv:65.0) Gecko/20100101 Firefox/65.0&#39;</span></span>
<span class="line"><span style="color:#F0F3F6;">}</span></span>
<span class="line"><span style="color:#BDC4CC;"># 1、创建请求对象，包装ua信息</span></span>
<span class="line"><span style="color:#F0F3F6;">req </span><span style="color:#FF9492;">=</span><span style="color:#F0F3F6;"> request.Request(</span><span style="color:#FFB757;">url</span><span style="color:#FF9492;">=</span><span style="color:#F0F3F6;">url,</span><span style="color:#FFB757;">headers</span><span style="color:#FF9492;">=</span><span style="color:#F0F3F6;">headers)</span></span>
<span class="line"><span style="color:#BDC4CC;"># 2、发送请求，获取响应对象</span></span>
<span class="line"><span style="color:#F0F3F6;">res </span><span style="color:#FF9492;">=</span><span style="color:#F0F3F6;"> request.urlopen(req)</span></span>
<span class="line"><span style="color:#BDC4CC;"># 3、提取响应内容</span></span>
<span class="line"><span style="color:#F0F3F6;">html </span><span style="color:#FF9492;">=</span><span style="color:#F0F3F6;"> res.read().decode(</span><span style="color:#ADDCFF;">&#39;utf-8&#39;</span><span style="color:#F0F3F6;">)</span></span>
<span class="line"><span style="color:#91CBFF;">print</span><span style="color:#F0F3F6;">(html)</span></span></code></pre></div><div class="language-" data-highlighter="shiki" data-ext="" data-title="" style="background-color:#0a0c10;color:#f0f3f6;"><pre class="shiki github-dark-high-contrast vp-code"><code><span class="line"><span>{</span></span>
<span class="line"><span>  &quot;args&quot;: {}, </span></span>
<span class="line"><span>  &quot;headers&quot;: {</span></span>
<span class="line"><span>    &quot;Accept-Encoding&quot;: &quot;identity&quot;, </span></span>
<span class="line"><span>    &quot;Host&quot;: &quot;httpbin.org&quot;, </span></span>
<span class="line"><span>    &quot;User-Agent&quot;: &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10.12; rv:65.0) Gecko/20100101 Firefox/65.0&quot;, </span></span>
<span class="line"><span>    &quot;X-Amzn-Trace-Id&quot;: &quot;Root=1-675ff631-440d851c1bec00c7130cb375&quot;</span></span>
<span class="line"><span>  }, </span></span>
<span class="line"><span>  &quot;origin&quot;: &quot;27.187.253.34&quot;, </span></span>
<span class="line"><span>  &quot;url&quot;: &quot;http://httpbin.org/get&quot;</span></span>
<span class="line"><span>}</span></span></code></pre></div><p>上述代码重构了<code>User-Agent</code>字符串信息，这样就解决了网站通过识别<code>User-Agent</code>来封杀爬虫程序的问题。当然这只是应对反爬策略的第一步。重构 UA 也可以通过其他模块实现，比如<code>requests</code>模块。</p><h2 id="构建user-agent代理池" tabindex="-1"><a class="header-anchor" href="#构建user-agent代理池"><span>构建User-Agent代理池</span></a></h2><p>在编写爬虫程序时，一般都会构建一个<code>User-Agent</code>（用户代理）池，就是把多个浏览器的 UA 信息放进列表中，然后再从中随机选择。构建用户代理池，能够避免总是使用一个 UA 来访问网站，因为短时间内总使用一个 UA 高频率访问的网站，可能会引起网站的警觉，从而封杀掉 IP。</p><h3 id="自定义ua代理池" tabindex="-1"><a class="header-anchor" href="#自定义ua代理池"><span>自定义UA代理池</span></a></h3><p>构建代理池的方法也非常简单，在 Pycharm 工作目录中定义一个<code>ua_info.py</code>文件，并将以下 UA 信息以列表的形式粘贴到该文件中：</p><div class="language-python" data-highlighter="shiki" data-ext="python" data-title="python" style="background-color:#0a0c10;color:#f0f3f6;"><pre class="shiki github-dark-high-contrast vp-code"><code><span class="line"><span style="color:#F0F3F6;">ua_list </span><span style="color:#FF9492;">=</span><span style="color:#F0F3F6;"> [</span></span>
<span class="line"><span style="color:#ADDCFF;">    &#39;Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1; Maxthon 2.0&#39;</span><span style="color:#F0F3F6;">,</span></span>
<span class="line"><span style="color:#ADDCFF;">    &#39;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_7_0) AppleWebKit/535.11 (KHTML, like Gecko) Chrome/17.0.963.56 Safari/535.11&#39;</span><span style="color:#F0F3F6;">,</span></span>
<span class="line"><span style="color:#ADDCFF;">    &#39;User-Agent:Opera/9.80 (Windows NT 6.1; U; en) Presto/2.8.131 Version/11.11&#39;</span><span style="color:#F0F3F6;">,</span></span>
<span class="line"><span style="color:#ADDCFF;">    &#39;Mozilla/5.0 (Windows NT 6.1; rv:2.0.1) Gecko/20100101 Firefox/4.0.1&#39;</span><span style="color:#F0F3F6;">,</span></span>
<span class="line"><span style="color:#ADDCFF;">    &#39;Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 6.0)&#39;</span><span style="color:#F0F3F6;">,</span></span>
<span class="line"><span style="color:#ADDCFF;">    &#39;Mozilla/5.0 (Windows; U; Windows NT 6.1; en-us) AppleWebKit/534.50 (KHTML, like Gecko) Version/5.1 Safari/534.50&#39;</span><span style="color:#F0F3F6;">,</span></span>
<span class="line"><span style="color:#ADDCFF;">    &#39;Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0&#39;</span><span style="color:#F0F3F6;">,</span></span>
<span class="line"><span style="color:#ADDCFF;">    &#39; Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1&#39;</span><span style="color:#F0F3F6;">,</span></span>
<span class="line"><span style="color:#ADDCFF;">    &#39;Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1&#39;</span><span style="color:#F0F3F6;">,</span></span>
<span class="line"><span style="color:#ADDCFF;">    &#39; Mozilla/5.0 (Macintosh; Intel Mac OS X 10.6; rv:2.0.1) Gecko/20100101 Firefox/4.0.1&#39;</span><span style="color:#F0F3F6;">,</span></span>
<span class="line"><span style="color:#F0F3F6;">]</span></span></code></pre></div><p>经过上述操作，用户代理池就构建成功。</p><h3 id="模块随机获取ua" tabindex="-1"><a class="header-anchor" href="#模块随机获取ua"><span>模块随机获取UA</span></a></h3><p>也可以使用专门第三方的模块来随机获取浏览器 UA 信息，不过该模块需要单独安装：</p><div class="language-shell" data-highlighter="shiki" data-ext="shell" data-title="shell" style="background-color:#0a0c10;color:#f0f3f6;"><pre class="shiki github-dark-high-contrast vp-code"><code><span class="line"><span style="color:#FFB757;">pip</span><span style="color:#ADDCFF;"> install</span><span style="color:#ADDCFF;"> fake-useragent</span></span></code></pre></div><div class="language-python" data-highlighter="shiki" data-ext="python" data-title="python" style="background-color:#0a0c10;color:#f0f3f6;"><pre class="shiki github-dark-high-contrast vp-code"><code><span class="line"><span style="color:#FF9492;">from</span><span style="color:#F0F3F6;"> fake_useragent </span><span style="color:#FF9492;">import</span><span style="color:#F0F3F6;"> UserAgent</span></span>
<span class="line"><span style="color:#BDC4CC;">#实例化一个对象</span></span>
<span class="line"><span style="color:#F0F3F6;">ua</span><span style="color:#FF9492;">=</span><span style="color:#F0F3F6;">UserAgent()</span></span>
<span class="line"><span style="color:#BDC4CC;">#随机获取一个浏览器ua</span></span>
<span class="line"><span style="color:#91CBFF;">print</span><span style="color:#F0F3F6;">(ua.chrome)</span></span>
<span class="line"><span style="color:#91CBFF;">print</span><span style="color:#F0F3F6;">(ua.firefox)</span></span></code></pre></div><div class="language-" data-highlighter="shiki" data-ext="" data-title="" style="background-color:#0a0c10;color:#f0f3f6;"><pre class="shiki github-dark-high-contrast vp-code"><code><span class="line"><span>Mozilla/5.0 (Linux; Android 10; K) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Mobile Safari/537.36</span></span>
<span class="line"><span>Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:133.0) Gecko/20100101 Firefox/133.0</span></span></code></pre></div><h2 id="url编码-解码" tabindex="-1"><a class="header-anchor" href="#url编码-解码"><span>URL编码/解码</span></a></h2><p>当 URL 路径或者查询参数中，带有中文或者特殊字符的时候，就需要对 URL 进行编码（采用十六进制编码格式）。URL 编码的原则是使用安全字符去表示那些不安全的字符。</p><h3 id="哪些字符需要编码" tabindex="-1"><a class="header-anchor" href="#哪些字符需要编码"><span>哪些字符需要编码</span></a></h3><p>URL 之所以需要编码，是因为 URL 中的某些字符会引起歧义，比如 URL 查询参数中包含了<code>&amp;</code>或者<code>%</code>就会造成服务器解析错误；再比如，URL 的编码格式采用的是 ASCII 码而非 Unicode 格式，这表明 URL 中不允许包含任何非 ASCII 字符（比如中文），否则就会造成 URL 解析错误。</p><p>URL 编码协议规定（RFC3986 协议）：URL 中只允许使用 ASCII 字符集可以显示的字符，比如英文字母、数字、和<code>- _ . ~ ! *</code>这 6 个特殊字符。当在 URL 中使用不属于 ASCII 字符集的字符时，就要使用特殊的符号对该字符进行编码，比如空格需要用<code>%20</code>来表示。</p><p>哪些字符需要编码，分为以下三种情况：</p><ul><li>ASCII 表中没有对应的可显示字符，例如，汉字。</li><li>不安全字符，包括：<code># &quot; % &lt;&gt; [] {} | \\ ^ \\</code> \`。</li><li>部分保留字符，即<code>&amp; / : ; = ? @</code>。</li></ul><table><thead><tr><th>字符</th><th>含义</th><th>十六进制值编码</th></tr></thead><tbody><tr><td>+</td><td>URL 中 + 号表示空格</td><td>%2B</td></tr><tr><td>空格</td><td>URL中的空格可以编码为 + 号或者 %20</td><td>%20</td></tr><tr><td>/</td><td>分隔目录和子目录</td><td>%2F</td></tr><tr><td>?</td><td>分隔实际的 URL 和参数</td><td>%3F</td></tr><tr><td>%</td><td>指定特殊字符</td><td>%25</td></tr><tr><td>#</td><td>表示书签</td><td>%23</td></tr><tr><td>&amp;</td><td>URL 中指定的参数间的分隔符</td><td>%26</td></tr><tr><td>=</td><td>URL 中指定参数的值</td><td>%3D</td></tr></tbody></table><h3 id="python实现编码与解码" tabindex="-1"><a class="header-anchor" href="#python实现编码与解码"><span>Python实现编码与解码</span></a></h3><p>Python 的标准库<code>urllib.parse</code>模块中提供了用来编码和解码的方法，分别是<code>urlencode()</code>与<code>unquote()</code>方法。</p><table><thead><tr><th>方法</th><th style="text-align:left;">说明</th></tr></thead><tbody><tr><td>urlencode()</td><td style="text-align:left;">实现了对 url 地址的编码操作</td></tr><tr><td>unquote()</td><td style="text-align:left;">将编码后的 url 地址进行还原，被称为解码</td></tr></tbody></table><h4 id="编码urlencode" tabindex="-1"><a class="header-anchor" href="#编码urlencode"><span>编码urlencode()</span></a></h4><div class="language-text" data-highlighter="shiki" data-ext="text" data-title="text" style="background-color:#0a0c10;color:#f0f3f6;"><pre class="shiki github-dark-high-contrast vp-code"><code><span class="line"><span>https://www.baidu.com/s?wd=爬虫</span></span></code></pre></div><div class="language-python" data-highlighter="shiki" data-ext="python" data-title="python" style="background-color:#0a0c10;color:#f0f3f6;"><pre class="shiki github-dark-high-contrast vp-code"><code><span class="line"><span style="color:#BDC4CC;">#导入parse模块</span></span>
<span class="line"><span style="color:#FF9492;">from</span><span style="color:#F0F3F6;"> urllib </span><span style="color:#FF9492;">import</span><span style="color:#F0F3F6;"> parse</span></span>
<span class="line"><span style="color:#BDC4CC;">#构建查询字符串字典</span></span>
<span class="line"><span style="color:#F0F3F6;">query_string </span><span style="color:#FF9492;">=</span><span style="color:#F0F3F6;"> {</span></span>
<span class="line"><span style="color:#ADDCFF;">	&#39;wd&#39;</span><span style="color:#F0F3F6;"> : </span><span style="color:#ADDCFF;">&#39;爬虫&#39;</span></span>
<span class="line"><span style="color:#F0F3F6;">}</span></span>
<span class="line"><span style="color:#BDC4CC;">#调用parse模块的urlencode()进行编码</span></span>
<span class="line"><span style="color:#F0F3F6;">result </span><span style="color:#FF9492;">=</span><span style="color:#F0F3F6;"> parse.urlencode(query_string)</span></span>
<span class="line"><span style="color:#BDC4CC;">#使用format函数格式化字符串，拼接url地址</span></span>
<span class="line"><span style="color:#F0F3F6;">url </span><span style="color:#FF9492;">=</span><span style="color:#ADDCFF;"> &#39;http://www.baidu.com/s?</span><span style="color:#FF9492;">{}</span><span style="color:#ADDCFF;">&#39;</span><span style="color:#F0F3F6;">.format(result)</span></span>
<span class="line"><span style="color:#91CBFF;">print</span><span style="color:#F0F3F6;">(url)</span></span></code></pre></div><p>输出结果：</p><div class="language-" data-highlighter="shiki" data-ext="" data-title="" style="background-color:#0a0c10;color:#f0f3f6;"><pre class="shiki github-dark-high-contrast vp-code"><code><span class="line"><span>wd=%E7%88%AC%E8%99%AB</span></span>
<span class="line"><span>http://www.baidu.com/s?wd=%E7%88%AC%E8%99%AB</span></span></code></pre></div><p>编码后的 URL 地址依然可以通过地网页址栏实现搜索功能。</p><p>除了使用<code>urlencode()</code>方法之外，也可以使用<code>quote(string)</code>方法实现编码 ：</p><div class="language-python" data-highlighter="shiki" data-ext="python" data-title="python" style="background-color:#0a0c10;color:#f0f3f6;"><pre class="shiki github-dark-high-contrast vp-code"><code><span class="line"><span style="color:#FF9492;">from</span><span style="color:#F0F3F6;"> urllib </span><span style="color:#FF9492;">import</span><span style="color:#F0F3F6;"> parse</span></span>
<span class="line"><span style="color:#BDC4CC;">#注意url的书写格式，和 urlencode存在不同</span></span>
<span class="line"><span style="color:#F0F3F6;">url </span><span style="color:#FF9492;">=</span><span style="color:#ADDCFF;"> &#39;http://www.baidu.com/s?wd=</span><span style="color:#FF9492;">{}</span><span style="color:#ADDCFF;">&#39;</span></span>
<span class="line"><span style="color:#F0F3F6;">word </span><span style="color:#FF9492;">=</span><span style="color:#91CBFF;"> input</span><span style="color:#F0F3F6;">(</span><span style="color:#ADDCFF;">&#39;请输入要搜索的内容:&#39;</span><span style="color:#F0F3F6;">)</span></span>
<span class="line"><span style="color:#BDC4CC;">#quote()只能对字符串进行编码</span></span>
<span class="line"><span style="color:#F0F3F6;">query_string </span><span style="color:#FF9492;">=</span><span style="color:#F0F3F6;"> parse.quote(word)</span></span>
<span class="line"><span style="color:#91CBFF;">print</span><span style="color:#F0F3F6;">(url.format(query_string))</span></span></code></pre></div><p>注意：<code>quote()</code>只能对字符串编码，而<code>urlencode()</code>可以直接对查询字符串字典进行编码。因此在定义 URL 时，需要注意两者之间的差异。</p><div class="language-python" data-highlighter="shiki" data-ext="python" data-title="python" style="background-color:#0a0c10;color:#f0f3f6;"><pre class="shiki github-dark-high-contrast vp-code"><code><span class="line"><span style="color:#BDC4CC;"># urllib.parse</span></span>
<span class="line"><span style="color:#F0F3F6;">urllib.parse.urlencode({</span><span style="color:#ADDCFF;">&#39;key&#39;</span><span style="color:#F0F3F6;">:</span><span style="color:#ADDCFF;">&#39;value&#39;</span><span style="color:#F0F3F6;">}) </span><span style="color:#BDC4CC;">#字典</span></span>
<span class="line"><span style="color:#F0F3F6;">urllib.parse.quote(string) </span><span style="color:#BDC4CC;">#字符串</span></span></code></pre></div><h4 id="解码unquote-string" tabindex="-1"><a class="header-anchor" href="#解码unquote-string"><span>解码unquote(string)</span></a></h4><p>解码是对编码后的 URL 进行还原的一种操作：</p><div class="language-python" data-highlighter="shiki" data-ext="python" data-title="python" style="background-color:#0a0c10;color:#f0f3f6;"><pre class="shiki github-dark-high-contrast vp-code"><code><span class="line"><span style="color:#FF9492;">from</span><span style="color:#F0F3F6;"> urllib </span><span style="color:#FF9492;">import</span><span style="color:#F0F3F6;"> parse</span></span>
<span class="line"><span style="color:#F0F3F6;">string </span><span style="color:#FF9492;">=</span><span style="color:#ADDCFF;"> &#39;</span><span style="color:#FF9492;">%E</span><span style="color:#ADDCFF;">7</span><span style="color:#FF9492;">%88%</span><span style="color:#ADDCFF;">AC</span><span style="color:#FF9492;">%E</span><span style="color:#ADDCFF;">8</span><span style="color:#FF9492;">%99%</span><span style="color:#ADDCFF;">AB&#39;</span></span>
<span class="line"><span style="color:#F0F3F6;">result </span><span style="color:#FF9492;">=</span><span style="color:#F0F3F6;"> parse.unquote(string)</span></span>
<span class="line"><span style="color:#91CBFF;">print</span><span style="color:#F0F3F6;">(result)</span></span></code></pre></div><p>输出结果：</p><div class="language-" data-highlighter="shiki" data-ext="" data-title="" style="background-color:#0a0c10;color:#f0f3f6;"><pre class="shiki github-dark-high-contrast vp-code"><code><span class="line"><span>爬虫</span></span></code></pre></div><h4 id="url地址拼接方式" tabindex="-1"><a class="header-anchor" href="#url地址拼接方式"><span>URL地址拼接方式</span></a></h4><p>除了使用<code>format()</code>函数外，还可以使用字符串相加，以及字符串占位符：</p><div class="language-python" data-highlighter="shiki" data-ext="python" data-title="python" style="background-color:#0a0c10;color:#f0f3f6;"><pre class="shiki github-dark-high-contrast vp-code"><code><span class="line"><span style="color:#BDC4CC;"># 1、字符串相加</span></span>
<span class="line"><span style="color:#F0F3F6;">  baseurl </span><span style="color:#FF9492;">=</span><span style="color:#ADDCFF;"> &#39;http://www.baidu.com/s?&#39;</span></span>
<span class="line"><span style="color:#F0F3F6;">  params</span><span style="color:#FF9492;">=</span><span style="color:#ADDCFF;">&#39;wd=</span><span style="color:#FF9492;">%E</span><span style="color:#ADDCFF;">7</span><span style="color:#FF9492;">%88%</span><span style="color:#ADDCFF;">AC</span><span style="color:#FF9492;">%E</span><span style="color:#ADDCFF;">8</span><span style="color:#FF9492;">%99%</span><span style="color:#ADDCFF;">AB&#39;</span></span>
<span class="line"><span style="color:#F0F3F6;">  url </span><span style="color:#FF9492;">=</span><span style="color:#F0F3F6;"> baseurl </span><span style="color:#FF9492;">+</span><span style="color:#F0F3F6;"> params</span></span>
<span class="line"></span>
<span class="line"><span style="color:#BDC4CC;"># 2、字符串格式化（占位符）</span></span>
<span class="line"><span style="color:#F0F3F6;">  params</span><span style="color:#FF9492;">=</span><span style="color:#ADDCFF;">&#39;wd=</span><span style="color:#FF9492;">%E</span><span style="color:#ADDCFF;">7</span><span style="color:#FF9492;">%88%</span><span style="color:#ADDCFF;">AC</span><span style="color:#FF9492;">%E</span><span style="color:#ADDCFF;">8</span><span style="color:#FF9492;">%99%</span><span style="color:#ADDCFF;">AB&#39;</span></span>
<span class="line"><span style="color:#F0F3F6;">  url </span><span style="color:#FF9492;">=</span><span style="color:#ADDCFF;"> &#39;http://www.baidu.com/s?</span><span style="color:#FF9492;">%s</span><span style="color:#ADDCFF;">&#39;</span><span style="color:#FF9492;">%</span><span style="color:#F0F3F6;"> params</span></span>
<span class="line"></span>
<span class="line"><span style="color:#BDC4CC;"># 3、format()方法</span></span>
<span class="line"><span style="color:#F0F3F6;">  url </span><span style="color:#FF9492;">=</span><span style="color:#ADDCFF;"> &#39;http://www.baidu.com/s?</span><span style="color:#FF9492;">{}</span><span style="color:#ADDCFF;">&#39;</span></span>
<span class="line"><span style="color:#F0F3F6;">  params</span><span style="color:#FF9492;">=</span><span style="color:#ADDCFF;">&#39;wd=</span><span style="color:#FF9492;">%E</span><span style="color:#ADDCFF;">7</span><span style="color:#FF9492;">%88%</span><span style="color:#ADDCFF;">AC</span><span style="color:#FF9492;">%E</span><span style="color:#ADDCFF;">8</span><span style="color:#FF9492;">%99%</span><span style="color:#ADDCFF;">AB&#39;</span></span>
<span class="line"><span style="color:#F0F3F6;">  url </span><span style="color:#FF9492;">=</span><span style="color:#F0F3F6;"> url.format(params)</span></span></code></pre></div><h2 id="爬虫实战案例" tabindex="-1"><a class="header-anchor" href="#爬虫实战案例"><span>爬虫实战案例</span></a></h2><p>首先我们对要编写的爬虫程序进行简单地分析，该程序可分为以下三个部分：</p><ul><li>拼接 url 地址</li><li>发送请求</li><li>将照片保存至本地</li></ul><div class="language-python" data-highlighter="shiki" data-ext="python" data-title="python" style="background-color:#0a0c10;color:#f0f3f6;"><pre class="shiki github-dark-high-contrast vp-code"><code><span class="line"><span style="color:#FF9492;">from</span><span style="color:#F0F3F6;"> urllib </span><span style="color:#FF9492;">import</span><span style="color:#F0F3F6;"> request,parse</span></span>
<span class="line"><span style="color:#BDC4CC;"># 1.拼url地址</span></span>
<span class="line"><span style="color:#F0F3F6;">url </span><span style="color:#FF9492;">=</span><span style="color:#ADDCFF;"> &#39;http://www.baidu.com/s?wd=</span><span style="color:#FF9492;">{}</span><span style="color:#ADDCFF;">&#39;</span></span>
<span class="line"><span style="color:#F0F3F6;">word </span><span style="color:#FF9492;">=</span><span style="color:#91CBFF;"> input</span><span style="color:#F0F3F6;">(</span><span style="color:#ADDCFF;">&#39;请输入搜索内容:&#39;</span><span style="color:#F0F3F6;">)</span></span>
<span class="line"><span style="color:#F0F3F6;">params </span><span style="color:#FF9492;">=</span><span style="color:#F0F3F6;"> parse.quote(word)</span></span>
<span class="line"><span style="color:#F0F3F6;">full_url </span><span style="color:#FF9492;">=</span><span style="color:#F0F3F6;"> url.format(params)</span></span>
<span class="line"><span style="color:#BDC4CC;"># 2.发请求保存到本地</span></span>
<span class="line"><span style="color:#F0F3F6;">headers </span><span style="color:#FF9492;">=</span><span style="color:#F0F3F6;"> {</span><span style="color:#ADDCFF;">&#39;User-Agent&#39;</span><span style="color:#F0F3F6;">:</span><span style="color:#ADDCFF;">&#39;Mozilla/5.0 (Windows NT 6.1; WOW64; rv:6.0) Gecko/20100101 Firefox/6.0&#39;</span><span style="color:#F0F3F6;">}</span></span>
<span class="line"><span style="color:#F0F3F6;">req </span><span style="color:#FF9492;">=</span><span style="color:#F0F3F6;"> request.Request(</span><span style="color:#FFB757;">url</span><span style="color:#FF9492;">=</span><span style="color:#F0F3F6;">full_url,</span><span style="color:#FFB757;">headers</span><span style="color:#FF9492;">=</span><span style="color:#F0F3F6;">headers)</span></span>
<span class="line"><span style="color:#F0F3F6;">res </span><span style="color:#FF9492;">=</span><span style="color:#F0F3F6;"> request.urlopen(req)</span></span>
<span class="line"><span style="color:#F0F3F6;">html </span><span style="color:#FF9492;">=</span><span style="color:#F0F3F6;"> res.read().decode(</span><span style="color:#ADDCFF;">&#39;utf-8&#39;</span><span style="color:#F0F3F6;">)</span></span>
<span class="line"><span style="color:#BDC4CC;"># 3.保存文件至当前目录</span></span>
<span class="line"><span style="color:#F0F3F6;">filename </span><span style="color:#FF9492;">=</span><span style="color:#F0F3F6;"> word </span><span style="color:#FF9492;">+</span><span style="color:#ADDCFF;"> &#39;.html&#39;</span></span>
<span class="line"><span style="color:#FF9492;">with</span><span style="color:#91CBFF;"> open</span><span style="color:#F0F3F6;">(filename,</span><span style="color:#ADDCFF;">&#39;w&#39;</span><span style="color:#F0F3F6;">,</span><span style="color:#FFB757;">encoding</span><span style="color:#FF9492;">=</span><span style="color:#ADDCFF;">&#39;utf-8&#39;</span><span style="color:#F0F3F6;">) </span><span style="color:#FF9492;">as</span><span style="color:#F0F3F6;"> f:</span></span>
<span class="line"><span style="color:#F0F3F6;">    f.write(html)</span></span></code></pre></div><h3 id="函数式编程修改程序" tabindex="-1"><a class="header-anchor" href="#函数式编程修改程序"><span>函数式编程修改程序</span></a></h3><div class="language-python" data-highlighter="shiki" data-ext="python" data-title="python" style="background-color:#0a0c10;color:#f0f3f6;"><pre class="shiki github-dark-high-contrast vp-code"><code><span class="line"><span style="color:#FF9492;">from</span><span style="color:#F0F3F6;"> urllib </span><span style="color:#FF9492;">import</span><span style="color:#F0F3F6;"> request</span></span>
<span class="line"><span style="color:#FF9492;">from</span><span style="color:#F0F3F6;"> urllib </span><span style="color:#FF9492;">import</span><span style="color:#F0F3F6;"> parse</span></span>
<span class="line"></span>
<span class="line"><span style="color:#BDC4CC;"># 拼接URL地址</span></span>
<span class="line"><span style="color:#FF9492;">def</span><span style="color:#DBB7FF;"> get_url</span><span style="color:#F0F3F6;">(word):</span></span>
<span class="line"><span style="color:#F0F3F6;">  url </span><span style="color:#FF9492;">=</span><span style="color:#ADDCFF;"> &#39;http://www.baidu.com/s?</span><span style="color:#FF9492;">{}</span><span style="color:#ADDCFF;">&#39;</span></span>
<span class="line"><span style="color:#BDC4CC;">  #此处使用urlencode()进行编码</span></span>
<span class="line"><span style="color:#F0F3F6;">  params </span><span style="color:#FF9492;">=</span><span style="color:#F0F3F6;"> parse.urlencode({</span><span style="color:#ADDCFF;">&#39;wd&#39;</span><span style="color:#F0F3F6;">:word})</span></span>
<span class="line"><span style="color:#F0F3F6;">  url </span><span style="color:#FF9492;">=</span><span style="color:#F0F3F6;"> url.format(params)</span></span>
<span class="line"><span style="color:#FF9492;">  return</span><span style="color:#F0F3F6;"> url</span></span>
<span class="line"></span>
<span class="line"><span style="color:#BDC4CC;"># 发请求,保存本地文件</span></span>
<span class="line"><span style="color:#FF9492;">def</span><span style="color:#DBB7FF;"> request_url</span><span style="color:#F0F3F6;">(url,filename):</span></span>
<span class="line"><span style="color:#F0F3F6;">  headers </span><span style="color:#FF9492;">=</span><span style="color:#F0F3F6;"> {</span><span style="color:#ADDCFF;">&#39;User-Agent&#39;</span><span style="color:#F0F3F6;">:</span><span style="color:#ADDCFF;">&#39;Mozilla/5.0 (Windows NT 6.1; WOW64; rv:6.0) Gecko/20100101 Firefox/6.0&#39;</span><span style="color:#F0F3F6;">}</span></span>
<span class="line"><span style="color:#BDC4CC;">  # 请求对象 + 响应对象 + 提取内容</span></span>
<span class="line"><span style="color:#F0F3F6;">  req </span><span style="color:#FF9492;">=</span><span style="color:#F0F3F6;"> request.Request(</span><span style="color:#FFB757;">url</span><span style="color:#FF9492;">=</span><span style="color:#F0F3F6;">url,</span><span style="color:#FFB757;">headers</span><span style="color:#FF9492;">=</span><span style="color:#F0F3F6;">headers)</span></span>
<span class="line"><span style="color:#F0F3F6;">  res </span><span style="color:#FF9492;">=</span><span style="color:#F0F3F6;"> request.urlopen(req)</span></span>
<span class="line"><span style="color:#F0F3F6;">  html </span><span style="color:#FF9492;">=</span><span style="color:#F0F3F6;"> res.read().decode(</span><span style="color:#ADDCFF;">&#39;utf-8&#39;</span><span style="color:#F0F3F6;">)</span></span>
<span class="line"><span style="color:#BDC4CC;">  # 保存文件至本地</span></span>
<span class="line"><span style="color:#FF9492;">  with</span><span style="color:#91CBFF;"> open</span><span style="color:#F0F3F6;">(filename,</span><span style="color:#ADDCFF;">&#39;w&#39;</span><span style="color:#F0F3F6;">,</span><span style="color:#FFB757;">encoding</span><span style="color:#FF9492;">=</span><span style="color:#ADDCFF;">&#39;utf-8&#39;</span><span style="color:#F0F3F6;">) </span><span style="color:#FF9492;">as</span><span style="color:#F0F3F6;"> f:</span></span>
<span class="line"><span style="color:#F0F3F6;">    f.write(html)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#BDC4CC;"># 主程序入口</span></span>
<span class="line"><span style="color:#FF9492;">if</span><span style="color:#91CBFF;"> __name__</span><span style="color:#FF9492;"> ==</span><span style="color:#ADDCFF;"> &#39;__main__&#39;</span><span style="color:#F0F3F6;">:</span></span>
<span class="line"><span style="color:#F0F3F6;">  word </span><span style="color:#FF9492;">=</span><span style="color:#91CBFF;"> input</span><span style="color:#F0F3F6;">(</span><span style="color:#ADDCFF;">&#39;请输入搜索内容:&#39;</span><span style="color:#F0F3F6;">)</span></span>
<span class="line"><span style="color:#F0F3F6;">  url </span><span style="color:#FF9492;">=</span><span style="color:#F0F3F6;"> get_url(word)</span></span>
<span class="line"><span style="color:#F0F3F6;">  filename </span><span style="color:#FF9492;">=</span><span style="color:#F0F3F6;"> word </span><span style="color:#FF9492;">+</span><span style="color:#ADDCFF;"> &#39;.html&#39;</span></span>
<span class="line"><span style="color:#F0F3F6;">  request_url(url,filename)</span></span></code></pre></div>`,83)]))}const F=a(p,[["render",o],["__file","python爬虫.html.vue"]]),i=JSON.parse('{"path":"/python/python%E7%88%AC%E8%99%AB.html","title":"","lang":"zh-CN","frontmatter":{"description":"第一个Python爬虫程序 下面使用 Python 内置的urllib库获取网页的 html 信息。注意，urllib库属于 Python 的标准库模块，无须单独安装，它是 Python 爬虫的常用模块。 获取网页html信息 1. 获取响应对象 向百度发起请求，获取百度首页的 HTML 信息： 上述代码会返回百度首页的响应对象， 其中urlopen(...","head":[["meta",{"property":"og:url","content":"https://0oWSQo0.github.io/wsq-blog/python/python%E7%88%AC%E8%99%AB.html"}],["meta",{"property":"og:description","content":"第一个Python爬虫程序 下面使用 Python 内置的urllib库获取网页的 html 信息。注意，urllib库属于 Python 的标准库模块，无须单独安装，它是 Python 爬虫的常用模块。 获取网页html信息 1. 获取响应对象 向百度发起请求，获取百度首页的 HTML 信息： 上述代码会返回百度首页的响应对象， 其中urlopen(..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-04-23T09:49:11.000Z"}],["meta",{"property":"article:modified_time","content":"2025-04-23T09:49:11.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2025-04-23T09:49:11.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"WSQ\\",\\"url\\":\\"https://0oWSQo0.github.com\\"}]}"]]},"headers":[{"level":2,"title":"第一个Python爬虫程序","slug":"第一个python爬虫程序","link":"#第一个python爬虫程序","children":[{"level":3,"title":"获取网页html信息","slug":"获取网页html信息","link":"#获取网页html信息","children":[]},{"level":3,"title":"urllib常用方法","slug":"urllib常用方法","link":"#urllib常用方法","children":[]}]},{"level":2,"title":"User-Agent（用户代理）","slug":"user-agent-用户代理","link":"#user-agent-用户代理","children":[{"level":3,"title":"爬虫程序UA信息","slug":"爬虫程序ua信息","link":"#爬虫程序ua信息","children":[]},{"level":3,"title":"重构爬虫UA信息","slug":"重构爬虫ua信息","link":"#重构爬虫ua信息","children":[]}]},{"level":2,"title":"构建User-Agent代理池","slug":"构建user-agent代理池","link":"#构建user-agent代理池","children":[{"level":3,"title":"自定义UA代理池","slug":"自定义ua代理池","link":"#自定义ua代理池","children":[]},{"level":3,"title":"模块随机获取UA","slug":"模块随机获取ua","link":"#模块随机获取ua","children":[]}]},{"level":2,"title":"URL编码/解码","slug":"url编码-解码","link":"#url编码-解码","children":[{"level":3,"title":"哪些字符需要编码","slug":"哪些字符需要编码","link":"#哪些字符需要编码","children":[]},{"level":3,"title":"Python实现编码与解码","slug":"python实现编码与解码","link":"#python实现编码与解码","children":[]}]},{"level":2,"title":"爬虫实战案例","slug":"爬虫实战案例","link":"#爬虫实战案例","children":[{"level":3,"title":"函数式编程修改程序","slug":"函数式编程修改程序","link":"#函数式编程修改程序","children":[]}]}],"git":{"createdTime":1745401751000,"updatedTime":1745401751000,"contributors":[{"name":"WSQ","email":"592786982@qq.com","commits":1}]},"readingTime":{"minutes":9.36,"words":2808},"filePathRelative":"python/python爬虫.md","localizedDate":"2025年4月23日","autoDesc":true}');export{F as comp,i as data};
